# ðŸ“– Publications


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICRA 2026</div><img src='images/SAGE.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[SAGE: Scene Graph-Aware Guidance and Execution for Long-Horizon Manipulation Tasks](https://arxiv.org/abs/2509.21928) 


-  we propose SAGE, a novel framework for Scene Graph-Aware Guidance and Execution in Long-Horizon Manipulation Tasks
</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICRA 2025</div><img src='images/1.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[LLGS: Unsupervised Gaussian Splatting for Image Enhancement and Reconstruction in Pure Dark Environment](https://arxiv.org/pdf/2503.18640)

<!-- [**Project**](https://suiuko.github.io/) <strong><span class='show_paper_citations' data='vq9Nz9UAAAAJ:UeHWp8X0CEIC'></span></strong> -->

-  we propose an unsupervised multi-view stereoscopic system based on Gaussian Splatting, called Low-Light Gaussian Splatting.
</div>
</div>



# ðŸ¤” Review & correction

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Review</div><img src='images/pointflow.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

4DGS point flow 
Convert 3DGS to a time series format and simultaneously use semantic-driven methods to track objects.

</div>
</div>

<!-- - -->


<!-- - -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Review</div><img src='images/FSAG.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[FSAG: Enhancing Human-to-Dexterous-Hand Finger-Specific Affordance Grounding via Diffusion Models](https://arxiv.org/abs/2601.08246) 


-  we propose a data-efficient framework, which is designed to bypass robot grasp data collection by exploiting the rich, object-centric semantic priors latent in pretrained generative diffusion models. 
</div>
</div>

<!-- - -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Review</div><img src='images/Meta-scoop.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Meta-Scoop: A Coarse-to-Precise Policy Learning Framework for
Precision Scooping Across Task Variations 


-  We have proposed a framework that progresses from rough to precise, enabling precise extraction operations in various task variations.
</div>
</div>

<!-- - -->

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Review</div><img src='images/triplet2track.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Triplet2Track: A Hierarchical Object-Centric Representation for
Reliable Long-Horizon Manipulation 


-  we introduce the Triplet-to-Track System (TTS), which represents a task as discrete, structural instanceâ€“spatial triplets, then compiles them into continuous tracks with physical priors that are inspectable, and finally executes actions.
</div>
</div>

# ðŸ¤– Some Work

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Review</div><img src='images/2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[LTCF-Net: A Transformer-Enhanced Dual-Channel Fourier Framework for Low-Light Image Restoration](https://arxiv.org/pdf/2411.15740) \\

[**Project**](https://suiuko.github.io/) <strong><span class='show_paper_citations' data='vq9Nz9UAAAAJ:qjMakFHDy7sC'></span></strong>

-  We introduce LTCF-Net, a novel network architecture designed for enhancing low-light images.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Review</div><img src='images/3.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Lighting SLAM Paths in Darkness: A Low-Light Augmented SLAM  with Hybrid Window Transformer-Mamba \\

[**Project**](https://suiuko.github.io/) <strong><span class='show_paper_citations' data=''></span></strong>
ðŸ“º **Video** [**Youtube**](https://youtu.be/YhrSdNbK-IU)

-  We propose Low-Light Enhanced SLAM with Hybrid Window Transformer-Mamba (HWTM-SLAM), a novel framework that integrates low-light image enhancement as a fundamental front-end component to address the fragility of traditional SLAM systems in dark environments.
</div>
</div>

